pekko {
  contrib {
    persistence {
      mongodb {
        mongo {
          driver = "pekko.contrib.persistence.mongodb.driver.ScalaDriverPersistenceExtension"

          // legacy approach
          urls = [ "localhost:27017" ]
          db = "pekko-persistence"

          // mongouri = "mongodb://localhost:27017/pekko-persistence"

          journal-collection = "pekko_persistence_journal"
          journal-index = "pekko_persistence_journal_index"
          journal-seq-nr-index = "max_sequence_sort"
          journal-tag-index = "journal_tag_index"
          # Write concerns are one of: Unacknowledged, Acknowledged, Journaled, ReplicaAcknowledged
          journal-write-concern = "Journaled"
          journal-wtimeout = 3s
          journal-fsync = false
          journal-automatic-upgrade = false

          snaps-collection = "pekko_persistence_snaps"
          snaps-index = "pekko_persistence_snaps_index"
          snaps-write-concern = "Journaled"
          snaps-wtimeout = 3s
          snaps-fsync = false

          realtime-enable-persistence = true
          realtime-collection = "pekko_persistence_realtime"
          realtime-collection-size = 104857600 // 100MB

          metadata-collection = "pekko_persistence_metadata"
          metadata-index = "pekko_persistence_metadata_index"

          use-legacy-serialization = false

          # suffixed collection names
          suffix-builder {
            # This character is used as a separator before suffix in collection names
            # If you provide a string longer than one character, its first character only will be used
            # If you provide an empty string, the default underscore (_) character will be used
            separator = "_"

            # Extend 'pekko.contrib.persistence.mongodb.CanSuffixCollectionNames' trait,
            # override its method, and provide its complete path in the 'class' field below.
            class = ""
          }

          # Set to true to drop suffixed collections when empty
          suffix-drop-empty-collections = false

          ## used with ScalaDriverMigrateToSuffixedCollections tool (see docs)
          suffix-migration {
            heavy-load = false
            empty-metadata = false

            # for these 3 properties, a value of zero means unlimited retries (not recommended)
            max-insert-retry = 1  // ignored if heavy-load = true
            max-delete-retry = 1  // ignored if heavy-load = true
            max-empty-metadata-retry = 1

            # if set to zero or negative value, defaults to 1
            parallelism = 1 // ignored if heavy-load = false
          }

          metrics-builder {
            class = ""
          }

          # Caches of collections created by the plugin
          collection-cache {

            # Cache of journal collections
            journal {
              # Implementation of the cache.
              # - Must be a subtype of MongoCollectionCache.
              # - Must have a public constructor taking a Config object as argument.
              # - Must be able to store the collection type of the chosen driver.
              #
              # If left empty, a default naive implementation with unbound memory consumption is used.
              class = ""

              # How long to retain the collection. Invalid or missing durations are treated as eternity.
              expire-after-write = Infinity
            }

            # Cache of snapshot collections
            snaps {
              class = ""
              expire-after-write = Infinity
            }

            # Cache of one realtime collection
            realtime {
              class = ""
              expire-after-write = Infinity

              # maximum size of the cache
              # 1 because the realtime collection is unique
              # default caches do not honor size bounds bigger than 1
              max-size = 1
            }

            # Cache of one metadata collection
            metadata {
              class = ""
              expire-after-write = Infinity

              # maximum size of the cache
              # 1 because the metadata collection is unique
              # default caches do not honor size bounds bigger than 1
              max-size = 1
            }
          }

          # Maximum number of entries retained in the read journal deduplication
          # caches (allEvents, eventsByTag, persistenceIds live query stages).
          # Set to 0 to disable eviction (unbounded, legacy behavior).
          read-journal-dedup-max-size = 10000
        }

        driver {
          official {
            minpoolsize = 0
            maxpoolsize = 100
            waitqueuemultiple = 5
            serverselectiontimeout = 30seconds
            waitqueuetimeout = 2minutes
            maxidletime = 0seconds
            maxlifetime = 0seconds
            connecttimeout = 10seconds
            sockettimeout = 0seconds
            socketkeepalive = false
            ssl = false
            sslinvalidhostnameallowed = false
            heartbeatfrequency = 10seconds
            minheartbeatfrequency = 500millis
            heartbeatconnecttimeout = 20seconds
            heartbeatsockettimeout = 20seconds
          }
        }
      }
    }
  }
}

# Used for journal write-side
pekko-contrib-persistence-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "thread-pool-executor"
  # Configuration for the thread pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 2
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 2.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 10
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 100
}

# Used for persistence queries
pekko-contrib-persistence-query-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "thread-pool-executor"
  # Configuration for the thread pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 2
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 10.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 60
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 100
}

# The following line will enable this plugin for journalling
# pekko.persistence.journal.plugin = "pekko-contrib-mongodb-persistence-journal"

pekko-contrib-mongodb-persistence-journal {
  # Class name of the plugin.
  class = "pekko.contrib.persistence.mongodb.MongoJournal"
  # Dispatcher for the plugin actor.
  plugin-dispatcher = "pekko-contrib-persistence-dispatcher"
}

# The following line will enable this plugin for snapshotting
# pekko.persistence.snapshot-store.plugin = "pekko-contrib-mongodb-persistence-snapshot"

pekko-contrib-mongodb-persistence-snapshot {
  # Class name of the plugin.
  class = "pekko.contrib.persistence.mongodb.MongoSnapshots"
  # Dispatcher for the plugin actor.
  plugin-dispatcher = "pekko-contrib-persistence-dispatcher"
}

# The following line will enable this plugin for read journal queries
# val readJournal = PersistenceQuery(actorSystem).readJournalFor("pekko-contrib-mongodb-persistence-readjournal")

pekko-contrib-mongodb-persistence-readjournal {
  # Class name of the plugin.
  class = "pekko.contrib.persistence.mongodb.MongoReadJournal"
  # Dispatcher for the plugin actor.
  plugin-dispatcher = "pekko-contrib-persistence-dispatcher"
}
